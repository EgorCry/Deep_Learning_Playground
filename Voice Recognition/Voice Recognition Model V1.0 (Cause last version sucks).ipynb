{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c556c74",
   "metadata": {},
   "source": [
    "## The reference \n",
    "### https://www.thepythoncode.com/article/gender-recognition-by-voice-using-tensorflow-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf7c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf4b749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/cv-other-train/sample-069205.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/cv-valid-train/sample-063134.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/cv-other-train/sample-080873.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/cv-other-train/sample-105595.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/cv-valid-train/sample-144613.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  gender\n",
       "0  data/cv-other-train/sample-069205.npy  female\n",
       "1  data/cv-valid-train/sample-063134.npy  female\n",
       "2  data/cv-other-train/sample-080873.npy  female\n",
       "3  data/cv-other-train/sample-105595.npy  female\n",
       "4  data/cv-valid-train/sample-144613.npy  female"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('balanced-all.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6c5c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66933</th>\n",
       "      <td>data/cv-valid-train/sample-171098.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66934</th>\n",
       "      <td>data/cv-other-train/sample-022864.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66935</th>\n",
       "      <td>data/cv-valid-train/sample-080933.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66936</th>\n",
       "      <td>data/cv-other-train/sample-012026.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66937</th>\n",
       "      <td>data/cv-other-train/sample-013841.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename gender\n",
       "66933  data/cv-valid-train/sample-171098.npy   male\n",
       "66934  data/cv-other-train/sample-022864.npy   male\n",
       "66935  data/cv-valid-train/sample-080933.npy   male\n",
       "66936  data/cv-other-train/sample-012026.npy   male\n",
       "66937  data/cv-other-train/sample-013841.npy   male"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdb1d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 66938\n",
      "Total male samples: 33469\n",
      "Total female samples: 33469\n"
     ]
    }
   ],
   "source": [
    "# get total samples\n",
    "n_samples = len(df)\n",
    "\n",
    "# get total male samples\n",
    "n_male_samples = len(df[df['gender'] == 'male'])\n",
    "\n",
    "# get total female samples\n",
    "n_female_samples = len(df[df['gender'] == 'female'])\n",
    "\n",
    "print(\"Total samples:\", n_samples)\n",
    "print(\"Total male samples:\", n_male_samples)\n",
    "print(\"Total female samples:\", n_female_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68ae4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_2_int = {\n",
    "    'male': 1,\n",
    "    'female': 0\n",
    "}\n",
    "\n",
    "\n",
    "def load_data(vector_length = 128):\n",
    "    \"\"\"A function to load gender recognition dataset from `data` folder\n",
    "    After the second run, this will load from results/features.npy and results/labels.npy files\n",
    "    as it is much faster!\"\"\"\n",
    "    # make sure results folder exists\n",
    "    if not os.path.isdir('results'):\n",
    "        os.mkdir('results')\n",
    "    # if features and labels already loaded individually and bundled, load them there instead\n",
    "    if os.path.isfile('results/features.npy') and os.path.isfile('results/labels.npy'):\n",
    "        X = np.load('results/features.npy')\n",
    "        y = np.load('results/labels.npy')\n",
    "        return X, y\n",
    "    # read dataframe\n",
    "    df = pd.read_csv('balanced-all.csv')\n",
    "    # get total samples\n",
    "    n_samples = len(df)\n",
    "\n",
    "    # get total male samples\n",
    "    n_male_samples = len(df[df['gender'] == 'male'])\n",
    "\n",
    "    # get total female samples\n",
    "    n_female_samples = len(df[df['gender'] == 'female'])\n",
    "\n",
    "    print(\"Total samples:\", n_samples)\n",
    "    print(\"Total male samples:\", n_male_samples)\n",
    "    print(\"Total female samples:\", n_female_samples)\n",
    "    \n",
    "    # initialize an empty array for all audio features\n",
    "    X = np.zeros((n_samples, vector_length))\n",
    "    # initialize an empty array for all audio labels (1 for male and 0 for female)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    for i, (filename, gender) in tqdm.tqdm(enumerate(zip(df['filename'], df['gender']))):\n",
    "        features = np.load(filename)\n",
    "        X[i] = features\n",
    "        y[i] = label_2_int[gender]\n",
    "    # save the audio features and labels into files\n",
    "    # if so won't load each one of them next run\n",
    "    np.save('results/features', X)\n",
    "    np.save('results/labels', y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea30feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.1, valid_size=0.1):\n",
    "    # split training set and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=7)\n",
    "    # split training set and validation set\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, random_state=7)\n",
    "    # return a dictionary of values\n",
    "    return {\n",
    "        'X_train': X_train,\n",
    "        'X_valid': X_valid,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_valid': y_valid,\n",
    "        'y_test': y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc766b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X, y = load_data()\n",
    "# split the data into training, validation and testing sets\n",
    "data = split_data(X, y, test_size=0.1, valid_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc09e06c",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beb127bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vector_length=128):\n",
    "    \"\"\"5 hidden dense layers from 256 units to 64, not the best model.\"\"\"\n",
    "    model = Sequential(name='Voice_Recognition')\n",
    "    model.add(Dense(256, input_shape=(vector_length,)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    # one output neuron with sigmoid activation function, 0 means female, 1 means male\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # using binary crossentropy as it's male/female classification (binary)\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    # print summary of the model\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "608619f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Voice_Recognition\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78916a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.5671 - accuracy: 0.7594 - val_loss: 0.3790 - val_accuracy: 0.8437\n",
      "Epoch 2/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.4182 - accuracy: 0.8324 - val_loss: 0.3382 - val_accuracy: 0.8704\n",
      "Epoch 3/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3836 - accuracy: 0.8507 - val_loss: 0.3116 - val_accuracy: 0.8772\n",
      "Epoch 4/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3617 - accuracy: 0.8590 - val_loss: 0.3163 - val_accuracy: 0.8778\n",
      "Epoch 5/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3557 - accuracy: 0.8657 - val_loss: 0.2935 - val_accuracy: 0.8833\n",
      "Epoch 6/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3382 - accuracy: 0.8703 - val_loss: 0.2857 - val_accuracy: 0.8875\n",
      "Epoch 7/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3370 - accuracy: 0.8690 - val_loss: 0.2786 - val_accuracy: 0.8858\n",
      "Epoch 8/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3204 - accuracy: 0.8764 - val_loss: 0.2793 - val_accuracy: 0.8913\n",
      "Epoch 9/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3219 - accuracy: 0.8778 - val_loss: 0.2662 - val_accuracy: 0.8984\n",
      "Epoch 10/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3152 - accuracy: 0.8802 - val_loss: 0.2581 - val_accuracy: 0.8986\n",
      "Epoch 11/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3105 - accuracy: 0.8839 - val_loss: 0.2520 - val_accuracy: 0.9026\n",
      "Epoch 12/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.3071 - accuracy: 0.8834 - val_loss: 0.2589 - val_accuracy: 0.8971\n",
      "Epoch 13/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.2951 - accuracy: 0.8892 - val_loss: 0.2724 - val_accuracy: 0.8921\n",
      "Epoch 14/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.2990 - accuracy: 0.8874 - val_loss: 0.2553 - val_accuracy: 0.9022\n",
      "Epoch 15/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.2924 - accuracy: 0.8881 - val_loss: 0.2912 - val_accuracy: 0.8861\n",
      "Epoch 16/100\n",
      "848/848 [==============================] - 3s 3ms/step - loss: 0.2904 - accuracy: 0.8909 - val_loss: 0.2533 - val_accuracy: 0.9029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x295d7e0b550>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tensorboard to view metrics\n",
    "tensorboard = TensorBoard(log_dir='logs')\n",
    "early_stopping = EarlyStopping(mode='min', patience=5, restore_best_weights=True)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "# train the model using the training set and validating using validation set\n",
    "model.fit(data['X_train'], data['y_train'], epochs=epochs, batch_size=batch_size, \n",
    "         validation_data=(data['X_valid'], data['y_valid']),\n",
    "         callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f0d13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to a file\n",
    "model.save('results/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c92a55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model using 6694 samples...\n",
      "Loss: 0.2564\n",
      "Accuracy: 90.56%\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model the testing set\n",
    "print(f\"Evaluating the model using {len(data['X_test'])} samples...\")\n",
    "loss, accuracy = model.evaluate(data['X_test'], data['y_test'], verbose=0)\n",
    "print(f'Loss: {loss:.4f}')\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda1f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model instead learning it again\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = keras.models.load_model('results/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d5ef2",
   "metadata": {},
   "source": [
    "## Testing the Model with your Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ca02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script for voice speakers\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "        Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc =  kwargs.get('mfcc')\n",
    "    chroma = kwargs.get('chroma')\n",
    "    mel = kwargs.get('mel')\n",
    "    contrast = kwargs.get('contrast')\n",
    "    tonnetz = kwargs.get('tonnetz')\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    if chroma or contrast:\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "    result = np.array([])\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "    if contrast:\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, contrast))\n",
    "    if tonnetz:\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e202af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
